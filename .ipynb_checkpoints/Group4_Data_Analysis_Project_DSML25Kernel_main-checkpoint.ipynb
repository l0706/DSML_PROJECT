{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c99d720",
   "metadata": {},
   "source": [
    "# DSML Data Analysis Project - Group 4  \n",
    "**_Predicting Traffic Volume from Ride-Hailing Trips in Chicago_**\n",
    "\n",
    "*By Louis, Malak, Lena, and Eero*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b6210",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7f7d1",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70cb265",
   "metadata": {},
   "source": [
    "**Transportation Network Providers - Trips (2023â€“2024):**\n",
    "https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips-2023-2024-/n26f-ihde/explore/query/SELECT%0A%20%20%60trip_id%60%2C%0A%20%20%60trip_start_timestamp%60%2C%0A%20%20%60trip_end_timestamp%60%2C%0A%20%20%60trip_seconds%60%2C%0A%20%20%60trip_miles%60%2C%0A%20%20%60percent_time_chicago%60%2C%0A%20%20%60percent_distance_chicago%60%2C%0A%20%20%60pickup_census_tract%60%2C%0A%20%20%60dropoff_census_tract%60%2C%0A%20%20%60pickup_community_area%60%2C%0A%20%20%60dropoff_community_area%60%2C%0A%20%20%60fare%60%2C%0A%20%20%60tip%60%2C%0A%20%20%60additional_charges%60%2C%0A%20%20%60trip_total%60%2C%0A%20%20%60shared_trip_authorized%60%2C%0A%20%20%60shared_trip_match%60%2C%0A%20%20%60trips_pooled%60%2C%0A%20%20%60pickup_centroid_latitude%60%2C%0A%20%20%60pickup_centroid_longitude%60%2C%0A%20%20%60pickup_centroid_location%60%2C%0A%20%20%60dropoff_centroid_latitude%60%2C%0A%20%20%60dropoff_centroid_longitude%60%2C%0A%20%20%60dropoff_centroid_location%60%0AORDER%20BY%20%60trip_start_timestamp%60%20DESC%20NULL%20FIRST/page/filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2522a51",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Prediction Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a405478d",
   "metadata": {},
   "source": [
    "We aim to predict **traffic volume** based on individual ride-hailing trips in Chicago, US.\n",
    "\n",
    "Our first approach is deriving this by dividing *trip seconds* by *trip miles*, representing the average duration per mile (higher values indicate greater congestion), thus indicating traffic volume/ defining a proxy for traffic volume.\n",
    "\n",
    "> `traffic_volume_proxy = trip_seconds / trip_miles`\n",
    "\n",
    "We plan on including the following **features**:\n",
    "- hour (extrcating from `trip_start_timestamp`)\n",
    "- day of the week (from `trip_start_timestamp`)\n",
    "- `pickup_community_area`\n",
    "- `dropoff_community_area`\n",
    "- `trip_seconds`\n",
    "- `trip_miles`\n",
    "- `trip_total` (excluding tips)\n",
    "- weather data (optional, using another database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acaeaf3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f847e9f",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7ecd14",
   "metadata": {},
   "source": [
    "Ride-hailing services use mobile apps such as Uber or Lyft to connect passengers to drivers, with the goal of providing fast and cost-effective transportation for users. Furthermore, reducing traffic congestion, lowering emissions, and increasing vehicle utilization are key incentives.\n",
    "\n",
    "In Chicago, transit via bus and rail is on the rise. In 2023, there was a total of 279.1 million rides, marking a 13% increase from 2022. Ride-hailing services have also seen increased adoption, especially in downtown areas. Fees for solo rides have even been implemented in the downtown area during peak times to encourage shared rides. Chicago remains one of the most congested US cities, especially during peak hours. Thus, the city is actively promoting shared mobility options, providing, for example, Divvy Bikes â€” a city-owned system for renting both bikes and scooters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4750e0",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3344d8",
   "metadata": {},
   "source": [
    "The given dataset provides us with a total of 1,743,696 individual trips, including various features. Below, we will go over each one and evaluate whether the feature will be useful for our prediction task, if we will only include data with a set value, or if it should be excluded during our data preparation.\n",
    "\n",
    "- **Trip ID**: Will be included as our primary key.\n",
    "\n",
    "- **Trip Start Time** & **Trip End Time**: Useful to our prediction task. Time is an important factor for traffic volume, which spikes during peak hours.\n",
    "\n",
    "- **Trip Seconds** & **Trip Miles**: Useful to our prediction task. Both are essential to our calculation of traffic volume.\n",
    "\n",
    "- **Percent Time Chicago** & **Percent Distance Chicago**: Only trips with 100% will be included. Trips with routes outside of Chicago do not fit our prediction task of modeling traffic volume *in Chicago*.\n",
    "\n",
    "- **Pickup Census Tract** & **Dropoff Census Tract**: Will be excluded. Compared to Pickup Community Area and Dropoff Community Area â€” which represent 77 large zones in Chicago â€” Census Tract identifies over 800 smaller zones. While more specific, they run a higher risk of missing data and reduce the likelihood of trips being comparable to each other.\n",
    "\n",
    "- **Pickup Community Area** & **Dropoff Community Area**: Useful for our prediction task. Traffic volume varies by location, and these provide a robust feature for space.\n",
    "\n",
    "- **Fare, Tip, Additional Charges, and Trip Total**: We will use trip total excluding tips, as this serves as an indicator of traffic congestion due to dynamic pricing used by apps such as Uber or Lyft. Only data with no tips will be used, as tipping is subjective and influenced by user generosity, culture, and driver service quality.\n",
    "\n",
    "- **Shared Trips Authorized, Shared Trips Match, and Trips Pooled**: Only data from trips that were not shared will be used, as trips stopping for other passengers would impact trip seconds without being a clear indication of traffic volume.\n",
    "\n",
    "- **Latitude, Longitude, and Location Coordinates**: Will be excluded for the same reasons as Census Tract â€” too specific and less useful for comparison for the prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189b1c5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78090de",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c072cb-743e-4334-bd00-f09adbf2b928",
   "metadata": {},
   "source": [
    "We filtered the raw data according to our data requirements stated above via the Chicago Data Portal and ended up with 32,752,518 individual trips.\n",
    "\n",
    "To reduce the data while preserving trips from different timeframes throughout 2023â€“2024, we initially considered to apply another filter base on the Trip ID â€” for example, including every trip containing \"197.\" After discussion, we concluded this approach could introduce bias. We decided on downloading all rows and afterwards reducing the data to every 100th entry via a Python script. The script was written by ChatGPT.\n",
    "\n",
    "We now have 327,526 individual trips to work with, fulfilling the condition of at least 100,000 rows in the raw data. With 77 different area codes â€” each for pickup and dropoff â€” this results in an average of approximately 55 identical trips per unique pickupâ€“dropoff area code combination.\n",
    "\n",
    "After exporting, we will clean the data before moving on to modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6237efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rds = pd.read_csv(\"Ridehailing_Chicago_sample327k.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0456359f",
   "metadata": {},
   "source": [
    "### Check Filter Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a01d9",
   "metadata": {},
   "source": [
    "We want to check if the following filters were applied accordingly:\n",
    "\n",
    "- 100% of the trip was driven in Chicago\n",
    "- No tip\n",
    "- No shared driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "303f5f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows match filters: True\n"
     ]
    }
   ],
   "source": [
    "rds['percent_time_chicago'] = rds['percent_time_chicago'].astype(str)\n",
    "rds['percent_distance_chicago'] = rds['percent_distance_chicago'].astype(str)\n",
    "\n",
    "all_conditions_met = (\n",
    "    (rds['shared_trip_match'] == False) &\n",
    "    (rds['shared_trip_authorized'] == False) &\n",
    "    (rds['tip'] == 0) &\n",
    "    (rds['percent_time_chicago'] == '1') &\n",
    "    (rds['percent_distance_chicago'] == '1')\n",
    ")\n",
    "\n",
    "print(\"All rows match filters:\", all_conditions_met.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08df1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/34] Lade Daten ab Offset 0 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[2/34] Lade Daten ab Offset 1,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[3/34] Lade Daten ab Offset 2,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[4/34] Lade Daten ab Offset 3,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[5/34] Lade Daten ab Offset 4,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[6/34] Lade Daten ab Offset 5,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[7/34] Lade Daten ab Offset 6,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[8/34] Lade Daten ab Offset 7,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[9/34] Lade Daten ab Offset 8,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[10/34] Lade Daten ab Offset 9,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[11/34] Lade Daten ab Offset 10,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[12/34] Lade Daten ab Offset 11,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[13/34] Lade Daten ab Offset 12,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[14/34] Lade Daten ab Offset 13,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[15/34] Lade Daten ab Offset 14,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[16/34] Lade Daten ab Offset 15,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[17/34] Lade Daten ab Offset 16,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[18/34] Lade Daten ab Offset 17,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[19/34] Lade Daten ab Offset 18,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[20/34] Lade Daten ab Offset 19,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[21/34] Lade Daten ab Offset 20,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[22/34] Lade Daten ab Offset 21,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[23/34] Lade Daten ab Offset 22,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[24/34] Lade Daten ab Offset 23,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[25/34] Lade Daten ab Offset 24,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[26/34] Lade Daten ab Offset 25,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[27/34] Lade Daten ab Offset 26,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[28/34] Lade Daten ab Offset 27,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[29/34] Lade Daten ab Offset 28,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[30/34] Lade Daten ab Offset 29,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[31/34] Lade Daten ab Offset 30,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[32/34] Lade Daten ab Offset 31,000,000 ...\n",
      "âœ… 1,000,000 Zeilen geladen.\n",
      "[33/34] Lade Daten ab Offset 32,000,000 ...\n",
      "âœ… 752,518 Zeilen geladen.\n",
      "[34/34] Lade Daten ab Offset 33,000,000 ...\n",
      "âœ… 0 Zeilen geladen.\n",
      "ðŸ”„ ZusammenfÃ¼hren der BlÃ¶cke ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_18968\\571679300.py:45: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat(dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”ƒ Sortiere nach trip_start_timestamp ...\n",
      "ðŸ“Š Ziehe jede 100. Zeile ...\n",
      "ðŸ’¾ Speichere Datei mit 327,526 Zeilen ...\n",
      "âœ… Fertig!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from io import StringIO\n",
    "\n",
    "# API-URL und Filter\n",
    "base_url = \"https://data.cityofchicago.org/resource/n26f-ihde.csv\"\n",
    "params_base = {\n",
    "    \"$where\": \"percent_time_chicago = 1 AND percent_distance_chicago = 1 AND tip = 0 AND shared_trip_authorized = false AND shared_trip_match = false\",\n",
    "    \"$limit\": 1000000\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "num_blocks = 34\n",
    "\n",
    "for i in range(num_blocks):\n",
    "    offset = i * 1_000_000\n",
    "    params = params_base.copy()\n",
    "    params[\"$offset\"] = offset\n",
    "    print(f\"[{i+1}/{num_blocks}] Lade Daten ab Offset {offset:,} ...\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Inhalt prÃ¼fen\n",
    "        if len(response.text.strip()) == 0:\n",
    "            print(f\"âš ï¸  Keine Daten empfangen bei Block {i+1}.\")\n",
    "            break\n",
    "        \n",
    "        chunk = pd.read_csv(StringIO(response.text))\n",
    "        dfs.append(chunk)\n",
    "        print(f\"âœ… {len(chunk):,} Zeilen geladen.\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fehler bei Block {i+1}: {e}\")\n",
    "        print(\"Inhalt der Antwort:\")\n",
    "        print(response.text[:1000])  # Nur die ersten 1000 Zeichen zeigen\n",
    "        break\n",
    "\n",
    "# Nur fortfahren, wenn Daten vorhanden\n",
    "if dfs:\n",
    "    print(\"ðŸ”„ ZusammenfÃ¼hren der BlÃ¶cke ...\")\n",
    "    full_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    print(\"ðŸ”ƒ Sortiere nach trip_start_timestamp ...\")\n",
    "    full_df['trip_start_timestamp'] = pd.to_datetime(full_df['trip_start_timestamp'], errors='coerce')\n",
    "    full_df = full_df.dropna(subset=['trip_start_timestamp'])\n",
    "    full_df = full_df.sort_values(by='trip_start_timestamp')\n",
    "\n",
    "    print(\"ðŸ“Š Ziehe jede 100. Zeile ...\")\n",
    "    sample_df = full_df.iloc[::100]\n",
    "\n",
    "    print(f\"ðŸ’¾ Speichere Datei mit {len(sample_df):,} Zeilen ...\")\n",
    "    sample_df.to_csv(\"Ridehailing_Chicago_sample327k.csv\", index=False)\n",
    "    print(\"âœ… Fertig!\")\n",
    "else:\n",
    "    print(\"âŒ Keine Daten zum Verarbeiten.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ac6e93",
   "metadata": {},
   "source": [
    "Nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66779c1c",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "593e28f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with `trip_miles == 0` or `trip_seconds == 0` (later for creation of traffic_volume proxy)\n",
    "rds = rds[(rds['trip_miles'] > 0) & (rds['trip_seconds'] > 0)]\n",
    "\n",
    "# Convert trip_start_times into datetime format\n",
    "rds['trip_start_timestamp'] = pd.to_datetime(rds['trip_start_timestamp'], errors='coerce') # errors=â€¦ handles invalid date strings (replaces them with NaT)\n",
    "# Extract `hour` and `day_of_week` from timestamps\n",
    "rds['hour'] = rds['trip_start_timestamp'].dt.hour\n",
    "rds['day_of_week'] = rds['trip_start_timestamp'].dt.dayofweek\n",
    "\n",
    "# ðŸŸ¡ TODOâ€¦ Other cleaning up/ filtering tasks (maybe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799f7cf0",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf713518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute traffic_volume feature\n",
    "rds['traffic_volume'] = rds['trip_seconds'] / rds['trip_miles']\n",
    "\n",
    "# ðŸŸ¡ TODO: Add weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9880f3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb006497",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf898f",
   "metadata": {},
   "source": [
    "After Business Understanding and Data Understanding and Preparation and before modeling or visualizing, we start by exploring key aspects of the dataset to understand patterns and context, e.g. â€¦\n",
    "\n",
    "- At what hour do most trips start?\n",
    "- On which day of the week are most trips taken?\n",
    "- What is the average traffic volume across all trips?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5232b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Most trips start at 18:00 with 12,569 trips.\n",
      "* Most trips happen on Saturday with 37,748 trips.\n",
      "* The average traffic volume is 4.39 minutes per mile.\n"
     ]
    }
   ],
   "source": [
    "# 1. Hour with most trips\n",
    "hour_counts = rds['hour'].value_counts().sort_index()\n",
    "peak_hour = hour_counts.idxmax()\n",
    "print(f\"* Most trips start at {peak_hour}:00 with {hour_counts[peak_hour]:,} trips.\")\n",
    "\n",
    "# 2. Day with most trips\n",
    "day_counts = rds['day_of_week'].value_counts().sort_index()\n",
    "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "peak_day_index = day_counts.idxmax()\n",
    "print(f\"* Most trips happen on {day_names[peak_day_index]} with {day_counts[peak_day_index]:,} trips.\")\n",
    "\n",
    "# 3. Average traffic volume\n",
    "avg_traffic_in_minutes = (rds['traffic_volume'].mean() / 60)\n",
    "print(f\"* The average traffic volume is {avg_traffic_in_minutes:.2f} minutes per mile.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724d908e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1128b3",
   "metadata": {},
   "source": [
    "## Next Title â€¦"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
